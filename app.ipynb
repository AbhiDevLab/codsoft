{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827376a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless numpy argparse pyopencl tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab01e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bd186",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.face_detector import FaceDetector\n",
    "from src.face_recognizer import FaceRecognizer\n",
    "from src.utils import load_images_from_folder, display_image, create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5da97b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def setup_project_structure():\n",
    "    \"\"\"Create the necessary directories for the project.\"\"\"\n",
    "    directories = [\n",
    "        'data/known_faces',\n",
    "        'data/test_images',\n",
    "        'models'\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        create_directory(directory)\n",
    "    \n",
    "    # Download Haar cascade if it doesn't exist\n",
    "    haar_path = 'models/haarcascade_frontalface_default.xml'\n",
    "    if not os.path.exists(haar_path):\n",
    "        print(\"Downloading Haar cascade model...\")\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(url, haar_path)\n",
    "        print(f\"Downloaded to {haar_path}\")\n",
    "\n",
    "def check_gpu_support():\n",
    "    \"\"\"Check if GPU acceleration is available.\"\"\"\n",
    "    # Check OpenCL support (for AMD GPUs)\n",
    "    opencl_available = cv2.ocl.haveOpenCL()\n",
    "    if opencl_available:\n",
    "        cv2.ocl.setUseOpenCL(True)\n",
    "        if cv2.ocl.useOpenCL():\n",
    "            print(\"OpenCL is available and enabled for OpenCV\")\n",
    "            \n",
    "            # Get OpenCL devices\n",
    "            import pyopencl as cl\n",
    "            try:\n",
    "                platforms = cl.get_platforms()\n",
    "                for platform in platforms:\n",
    "                    print(f\"Platform: {platform.name}\")\n",
    "                    devices = platform.get_devices()\n",
    "                    for device in devices:\n",
    "                        if device.type == cl.device_type.GPU:\n",
    "                            print(f\"  GPU Device: {device.name}\")\n",
    "                            return True\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting OpenCL devices: {e}\")\n",
    "        else:\n",
    "            print(\"OpenCL is available but could not be enabled\")\n",
    "    else:\n",
    "        print(\"OpenCL is not available\")\n",
    "    \n",
    "    # Check TensorFlow GPU support\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            print(f\"TensorFlow can access {len(gpus)} GPU(s):\")\n",
    "            for gpu in gpus:\n",
    "                print(f\"  {gpu.name}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"TensorFlow cannot access any GPUs\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking TensorFlow GPU support: {e}\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "def train_face_recognition(data_dir='data/known_faces', method='eigenfaces', use_gpu=True):\n",
    "    \"\"\"Train the face recognition model.\"\"\"\n",
    "    # Initialize face detector and recognizer\n",
    "    detector = FaceDetector(method='dnn_gpu' if use_gpu else 'haar', use_gpu=use_gpu)\n",
    "    recognizer = FaceRecognizer(method=method, use_gpu=use_gpu)\n",
    "    \n",
    "    # Load training images\n",
    "    print(f\"Loading training images from {data_dir}...\")\n",
    "    images, labels = load_images_from_folder(data_dir)\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No training images found. Please add images to the data/known_faces directory.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images with {len(set(labels))} unique labels.\")\n",
    "    \n",
    "    # Extract faces from images\n",
    "    faces = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for img, label in zip(images, labels):\n",
    "        detected_faces = detector.detect_faces(img)\n",
    "        \n",
    "        if len(detected_faces) == 1:  # Only use images with exactly one face\n",
    "            face_img = recognizer.extract_faces(img, detected_faces)[0]\n",
    "            faces.append(face_img)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    detection_time = time.time() - start_time\n",
    "    print(f\"Face detection completed in {detection_time:.2f} seconds\")\n",
    "    \n",
    "    if not faces:\n",
    "        print(\"No faces detected in training images.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Extracted {len(faces)} faces for training.\")\n",
    "    \n",
    "    # Train the recognizer\n",
    "    print(\"Training face recognizer...\")\n",
    "    start_time = time.time()\n",
    "    recognizer.train(faces, valid_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = f'models/face_recognizer_{method}.xml'\n",
    "    recognizer.save_model(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return recognizer\n",
    "\n",
    "def recognize_faces_in_image(image_path, detector, recognizer):\n",
    "    \"\"\"Recognize faces in an image.\"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Detect faces\n",
    "    start_time = time.time()\n",
    "    faces = detector.detect_faces(image)\n",
    "    detection_time = time.time() - start_time\n",
    "    print(f\"Detected {len(faces)} faces in {detection_time:.2f} seconds.\")\n",
    "    \n",
    "    # Draw rectangles and labels\n",
    "    result_image = image.copy()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Recognize the face\n",
    "        label, confidence = recognizer.predict(face)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(result_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label\n",
    "        text = f\"{label} ({confidence:.2f}%)\"\n",
    "        cv2.putText(result_image, text, (x, y-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "    recognition_time = time.time() - start_time\n",
    "    print(f\"Recognition completed in {recognition_time:.2f} seconds.\")\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "def process_video(video_path, detector, recognizer, output_path=None, display=True):\n",
    "    \"\"\"Process a video for face recognition.\"\"\"\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Could not open video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Create video writer if output path is provided\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Performance metrics\n",
    "    frame_count = 0\n",
    "    total_detection_time = 0\n",
    "    total_recognition_time = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect faces\n",
    "        detection_start = time.time()\n",
    "        faces = detector.detect_faces(frame)\n",
    "        detection_time = time.time() - detection_start\n",
    "        total_detection_time += detection_time\n",
    "        \n",
    "        # Draw rectangles and labels\n",
    "        recognition_start = time.time()\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Recognize the face\n",
    "            try:\n",
    "                label, confidence = recognizer.predict(face)\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw label\n",
    "                text = f\"{label} ({confidence:.2f}%)\"\n",
    "                cv2.putText(frame, text, (x, y-10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error recognizing face: {e}\")\n",
    "        \n",
    "        recognition_time = time.time() - recognition_start\n",
    "        total_recognition_time += recognition_time\n",
    "        \n",
    "        # Add FPS info to frame\n",
    "        current_fps = 1.0 / (detection_time + recognition_time) if (detection_time + recognition_time) > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {current_fps:.2f}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "        # Write the frame\n",
    "        if output_path:\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Display the frame\n",
    "        if display:\n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "            \n",
    "            # Break on 'q' key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    # Calculate and display performance metrics\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "    avg_detection_time = total_detection_time / frame_count if frame_count > 0 else 0\n",
    "    avg_recognition_time = total_recognition_time / frame_count if frame_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "    print(f\"Average detection time per frame: {avg_detection_time*1000:.2f} ms\")\n",
    "    print(f\"Average recognition time per frame: {avg_recognition_time*1000:.2f} ms\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Face Detection and Recognition with GPU Acceleration')\n",
    "    parser.add_argument('--mode', type=str, default='train', \n",
    "                        choices=['setup', 'check_gpu', 'train', 'image', 'video', 'webcam', 'benchmark'],\n",
    "                        help='Operation mode')\n",
    "    parser.add_argument('--method', type=str, default='eigenfaces',\n",
    "                        choices=['eigenfaces', 'lbph', 'ml', 'deep'],\n",
    "                        help='Face recognition method')\n",
    "    parser.add_argument('--detector', type=str, default='dnn_gpu',\n",
    "                        choices=['haar', 'dnn', 'dnn_gpu'],\n",
    "                        help='Face detection method')\n",
    "    parser.add_argument('--input', type=str, help='Input image or video path')\n",
    "    parser.add_argument('--output', type=str, help='Output path for processed video')\n",
    "    parser.add_argument('--no-gpu', action='store_true', help='Disable GPU acceleration')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    use_gpu = not args.no_gpu\n",
    "    \n",
    "    if args.mode == 'setup':\n",
    "        setup_project_structure()\n",
    "        print(\"Project structure set up successfully.\")\n",
    "    \n",
    "    elif args.mode == 'check_gpu':\n",
    "        gpu_available = check_gpu_support()\n",
    "        if gpu_available:\n",
    "            print(\"\\nGPU acceleration is available and can be used.\")\n",
    "        else:\n",
    "            print(\"\\nGPU acceleration is not available. The application will run on CPU.\")\n",
    "    \n",
    "    elif args.mode == 'train':\n",
    "        recognizer = train_face_recognition(method=args.method, use_gpu=use_gpu)\n",
    "        if recognizer:\n",
    "            print(\"Training completed successfully.\")\n",
    "    \n",
    "    elif args.mode == 'image':\n",
    "        if not args.input:\n",
    "            print(\"Please provide an input image path with --input.\")\n",
    "            return\n",
    "        \n",
    "        # Load models\n",
    "        detector = FaceDetector(method=args.detector, use_gpu=use_gpu)\n",
    "        recognizer = FaceRecognizer(method=args.method, use_gpu=use_gpu)\n",
    "        \n",
    "        model_path = f'models/face_recognizer_{args.method}.xml'\n",
    "        if not os.path.exists(model_path) and args.method != 'deep':\n",
    "            print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "            return\n",
    "        elif args.method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "            print(f\"Deep learning model not found. Please train the model first.\")\n",
    "            return\n",
    "        \n",
    "        recognizer.load_model(model_path)\n",
    "        \n",
    "        # Process the image\n",
    "        result = recognize_faces_in_image(args.input, detector, recognizer)\n",
    "        \n",
    "        if result is not None:\n",
    "            # Save the result if output path is provided\n",
    "            if args.output:\n",
    "                cv2.imwrite(args.output, result)\n",
    "                print(f\"Result saved to {args.output}\")\n",
    "            \n",
    "            # Display the result\n",
    "            display_image(result, title=\"Face Recognition Result\")\n",
    "    \n",
    "    elif args.mode == 'video':\n",
    "        if not args.input:\n",
    "            print(\"Please provide an input video path with --input.\")\n",
    "            return\n",
    "        \n",
    "        # Load models\n",
    "        detector = FaceDetector(method=args.detector, use_gpu=use_gpu)\n",
    "        recognizer = FaceRecognizer(method=args.method, use_gpu=use_gpu)\n",
    "        \n",
    "        model_path = f'models/face_recognizer_{args.method}.xml'\n",
    "        if not os.path.exists(model_path) and args.method != 'deep':\n",
    "            print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "            return\n",
    "        elif args.method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "            print(f\"Deep learning model not found. Please train the model first.\")\n",
    "            return\n",
    "        \n",
    "        recognizer.load_model(model_path)\n",
    "        \n",
    "        # Process the video\n",
    "        process_video(args.input, detector, recognizer, args.output)\n",
    "    \n",
    "    elif args.mode == 'webcam':\n",
    "        # Load models\n",
    "        detector = FaceDetector(method=args.detector, use_gpu=use_gpu)\n",
    "        recognizer = FaceRecognizer(method=args.method, use_gpu=use_gpu)\n",
    "        \n",
    "        model_path = f'models/face_recognizer_{args.method}.xml'\n",
    "        if not os.path.exists(model_path) and args.method != 'deep':\n",
    "            print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "            return\n",
    "        elif args.method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "            print(f\"Deep learning model not found. Please train the model first.\")\n",
    "            return\n",
    "        \n",
    "        recognizer.load_model(model_path)\n",
    "        \n",
    "        # Process webcam feed\n",
    "        process_video(0, detector, recognizer, args.output)\n",
    "    \n",
    "    elif args.mode == 'benchmark':\n",
    "        # Run performance benchmark\n",
    "        print(\"Running performance benchmark...\")\n",
    "        \n",
    "        # Check GPU availability\n",
    "        gpu_available = check_gpu_support()\n",
    "        \n",
    "        # Test different detection methods\n",
    "        detection_methods = ['haar', 'dnn', 'dnn_gpu'] if gpu_available else ['haar', 'dnn']\n",
    "        recognition_methods = ['eigenfaces', 'lbph', 'ml', 'deep'] if gpu_available else ['eigenfaces', 'lbph', 'ml']\n",
    "        \n",
    "        # Benchmark detection methods\n",
    "        print(\"\\nBenchmarking face detection methods:\")\n",
    "        for method in detection_methods:\n",
    "            detector = FaceDetector(method=method, use_gpu=use_gpu)\n",
    "            \n",
    "            # Test on a sample image\n",
    "            if args.input:\n",
    "                image = cv2.imread(args.input)\n",
    "                if image is not None:\n",
    "                    start_time = time.time()\n",
    "                    faces = detector.detect_faces(image)\n",
    "                    detection_time = time.time() - start_time\n",
    "                    print(f\"Method: {method}, Detected faces: {len(faces)}, Time: {detection_time:.4f} seconds\")\n",
    "        \n",
    "        # Benchmark recognition methods (if models are available)\n",
    "        print(\"\\nBenchmarking face recognition methods:\")\n",
    "        for method in recognition_methods:\n",
    "            model_path = f'models/face_recognizer_{method}.xml'\n",
    "            if os.path.exists(model_path) or (method == 'deep' and os.path.exists(model_path.replace('.xml', '.h5'))):\n",
    "                recognizer = FaceRecognizer(method=method, use_gpu=use_gpu)\n",
    "                recognizer.load_model(model_path)\n",
    "                \n",
    "                # Test on a sample image with detected face\n",
    "                if args.input:\n",
    "                    image = cv2.imread(args.input)\n",
    "                    if image is not None:\n",
    "                        detector = FaceDetector(method='dnn_gpu' if gpu_available else 'dnn')\n",
    "                        faces = detector.detect_faces(image)\n",
    "                        \n",
    "                        if faces:\n",
    "                            face = image[faces[0][1]:faces[0][1]+faces[0][3], faces[0][0]:faces[0][0]+faces[0][2]]\n",
    "                            \n",
    "                            start_time = time.time()\n",
    "                            label, confidence = recognizer.predict(face)\n",
    "                            recognition_time = time.time() - start_time\n",
    "                            \n",
    "                            print(f\"Method: {method}, Recognized as: {label}, Confidence: {confidence:.2f}%, Time: {recognition_time:.4f} seconds\")\n",
    "            else:\n",
    "                print(f\"Method: {method}, Model not found. Skipping benchmark.\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
