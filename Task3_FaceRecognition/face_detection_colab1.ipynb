{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiDevLab/codsoft/blob/main/Task3_FaceRecognition/face_detection_colab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2351bc0",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "f2351bc0"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless numpy matplotlib scikit-learn pillow tensorflow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import urllib.request\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Memory growth enabled for GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error configuring GPU: {e}\")\n",
        "\n",
        "directories = [\n",
        "    'data/known_faces',\n",
        "    'data/test_images',\n",
        "    'models'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "haar_path = 'models/haarcascade_frontalface_default.xml'\n",
        "if not os.path.exists(haar_path):\n",
        "    print(\"Downloading Haar cascade model...\")\n",
        "    url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "    urllib.request.urlretrieve(url, haar_path)\n",
        "    print(f\"Downloaded to {haar_path}\")\n",
        "\n",
        "prototxt_path = 'models/deploy.prototxt'\n",
        "model_path = 'models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "if not os.path.exists(prototxt_path):\n",
        "    print(\"Downloading DNN prototxt...\")\n",
        "    prototxt_url = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\"\n",
        "    urllib.request.urlretrieve(prototxt_url, prototxt_path)\n",
        "    print(f\"Downloaded to {prototxt_path}\")\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading DNN model...\")\n",
        "    model_url = \"https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "    urllib.request.urlretrieve(model_url, model_path)\n",
        "    print(f\"Downloaded to {model_path}\")\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for person_name in os.listdir(folder):\n",
        "        person_folder = os.path.join(folder, person_name)\n",
        "\n",
        "        if not os.path.isdir(person_folder):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(person_folder):\n",
        "            img_path = os.path.join(person_folder, filename)\n",
        "\n",
        "            if not os.path.isfile(img_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    images.append(img)\n",
        "                    labels.append(person_name)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def display_image(image, title=None, figsize=(10, 8)):\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def benchmark_gpu():\n",
        "    results = {}\n",
        "\n",
        "    try:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            data_size = 1000\n",
        "            a = tf.random.normal((data_size, data_size))\n",
        "            b = tf.random.normal((data_size, data_size))\n",
        "\n",
        "            c = tf.matmul(a, b)\n",
        "\n",
        "            start_time = time.time()\n",
        "            c = tf.matmul(a, b)\n",
        "            c_val = c.numpy()\n",
        "            end_time = time.time()\n",
        "\n",
        "            for gpu in gpus:\n",
        "                results[gpu.name.decode('utf-8')] = {\n",
        "                    'type': 'TensorFlow',\n",
        "                    'time': end_time - start_time,\n",
        "                    'data_size': data_size\n",
        "                }\n",
        "\n",
        "                print(f\"TensorFlow test on {gpu.name.decode('utf-8')} completed in {end_time - start_time:.4f} seconds\")\n",
        "        else:\n",
        "            print(\"TensorFlow cannot access any GPUs\")\n",
        "\n",
        "            data_size = 1000\n",
        "            a = np.random.rand(data_size, data_size).astype(np.float32)\n",
        "            b = np.random.rand(data_size, data_size).astype(np.float32)\n",
        "\n",
        "            start_time = time.time()\n",
        "            c = np.matmul(a, b)\n",
        "            end_time = time.time()\n",
        "\n",
        "            results['CPU'] = {\n",
        "                'type': 'NumPy',\n",
        "                'time': end_time - start_time,\n",
        "                'data_size': data_size\n",
        "            }\n",
        "\n",
        "            print(f\"CPU test completed in {end_time - start_time:.4f} seconds\")\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow benchmark failed: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "class FaceDetector:\n",
        "    def __init__(self, method='dnn', model_path=None):\n",
        "        self.method = method\n",
        "\n",
        "        if method == 'haar':\n",
        "            if model_path is None:\n",
        "                model_path = 'models/haarcascade_frontalface_default.xml'\n",
        "            self.detector = cv2.CascadeClassifier(model_path)\n",
        "        elif method == 'dnn':\n",
        "            prototxt_path = 'models/deploy.prototxt'\n",
        "            model_path = 'models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "            self.detector = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
        "\n",
        "            try:\n",
        "                if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
        "                    self.detector.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "                    self.detector.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "                    print(\"Using CUDA for DNN face detection\")\n",
        "            except:\n",
        "                print(\"CUDA not available for OpenCV, using CPU\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported detection method: {method}\")\n",
        "\n",
        "    def detect_faces(self, image, min_confidence=0.5):\n",
        "        if self.method == 'haar':\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            faces = self.detector.detectMultiScale(\n",
        "                gray,\n",
        "                scaleFactor=1.1,\n",
        "                minNeighbors=5,\n",
        "                minSize=(30, 30)\n",
        "            )\n",
        "            return faces\n",
        "\n",
        "        elif self.method == 'dnn':\n",
        "            h, w = image.shape[:2]\n",
        "            blob = cv2.dnn.blobFromImage(\n",
        "                cv2.resize(image, (300, 300)),\n",
        "                1.0, (300, 300),\n",
        "                (104.0, 177.0, 123.0)\n",
        "            )\n",
        "\n",
        "            self.detector.setInput(blob)\n",
        "            detections = self.detector.forward()\n",
        "\n",
        "            faces = []\n",
        "            for i in range(detections.shape[2]):\n",
        "                confidence = detections[0, 0, i, 2]\n",
        "\n",
        "                if confidence > min_confidence:\n",
        "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "                    faces.append((startX, startY, endX - startX, endY - startY))\n",
        "\n",
        "            return faces\n",
        "\n",
        "    def draw_faces(self, image, faces, color=(0, 255, 0), thickness=2):\n",
        "        img_copy = image.copy()\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(img_copy, (x, y), (x + w, y + h), color, thickness)\n",
        "        return img_copy\n",
        "\n",
        "class FaceRecognizer:\n",
        "    def __init__(self, method='eigenfaces'):\n",
        "        self.method = method\n",
        "        self.face_size = (100, 100)\n",
        "\n",
        "        if method == 'eigenfaces':\n",
        "            self.recognizer = cv2.face.EigenFaceRecognizer_create()\n",
        "        elif method == 'lbph':\n",
        "            self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "        elif method == 'ml':\n",
        "            self.recognizer = SVC(kernel='linear', probability=True)\n",
        "            self.label_encoder = LabelEncoder()\n",
        "        elif method == 'deep':\n",
        "            self._create_deep_model()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported recognition method: {method}\")\n",
        "\n",
        "    def _create_deep_model(self):\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "        ])\n",
        "\n",
        "        self.deep_model = model\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def preprocess_face(self, face):\n",
        "        face = cv2.resize(face, self.face_size)\n",
        "\n",
        "        if len(face.shape) == 3:\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        face = cv2.equalizeHist(face)\n",
        "\n",
        "        return face\n",
        "\n",
        "    def extract_faces(self, image, face_locations):\n",
        "        faces = []\n",
        "        for (x, y, w, h) in face_locations:\n",
        "            face = image[y:y+h, x:x+w]\n",
        "            faces.append(self.preprocess_face(face))\n",
        "        return faces\n",
        "\n",
        "    def train(self, faces, labels):\n",
        "        if self.method in ['eigenfaces', 'lbph']:\n",
        "            self.recognizer.train(faces, np.array(labels))\n",
        "\n",
        "        elif self.method == 'ml':\n",
        "            flattened_faces = [face.flatten() for face in faces]\n",
        "            encoded_labels = self.label_encoder.fit_transform(labels)\n",
        "            self.recognizer.fit(flattened_faces, encoded_labels)\n",
        "\n",
        "        elif self.method == 'deep':\n",
        "            encoded_labels = self.label_encoder.fit_transform(labels)\n",
        "            num_classes = len(self.label_encoder.classes_)\n",
        "\n",
        "            if len(self.deep_model.layers) == 10:\n",
        "                self.deep_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "            self.deep_model.compile(\n",
        "                optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            faces_array = np.array([face.reshape(self.face_size[0], self.face_size[1], 1) for face in faces])\n",
        "\n",
        "            faces_array = faces_array / 255.0\n",
        "\n",
        "            self.deep_model.fit(\n",
        "                faces_array,\n",
        "                encoded_labels,\n",
        "                epochs=10,\n",
        "                batch_size=32,\n",
        "                validation_split=0.2\n",
        "            )\n",
        "\n",
        "    def predict(self, face):\n",
        "        face = self.preprocess_face(face)\n",
        "\n",
        "        if self.method in ['eigenfaces', 'lbph']:\n",
        "            label, confidence = self.recognizer.predict(face)\n",
        "            return label, confidence\n",
        "\n",
        "        elif self.method == 'ml':\n",
        "            face_flattened = face.flatten().reshape(1, -1)\n",
        "            label = self.recognizer.predict(face_flattened)[0]\n",
        "            proba = self.recognizer.predict_proba(face_flattened)[0]\n",
        "            confidence = proba[label] * 100\n",
        "\n",
        "            original_label = self.label_encoder.inverse_transform([label])[0]\n",
        "            return original_label, confidence\n",
        "\n",
        "        elif self.method == 'deep':\n",
        "            face_array = face.reshape(1, self.face_size[0], self.face_size[1], 1) / 255.0\n",
        "\n",
        "            predictions = self.deep_model.predict(face_array)\n",
        "            label_index = np.argmax(predictions[0])\n",
        "            confidence = predictions[0][label_index] * 100\n",
        "\n",
        "            original_label = self.label_encoder.inverse_transform([label_index])[0]\n",
        "            return original_label, confidence\n",
        "\n",
        "    def save_model(self, path):\n",
        "        if self.method in ['eigenfaces', 'lbph']:\n",
        "            self.recognizer.save(path)\n",
        "\n",
        "        elif self.method == 'ml':\n",
        "            with open(path, 'wb') as f:\n",
        "                pickle.dump({\n",
        "                    'model': self.recognizer,\n",
        "                    'encoder': self.label_encoder\n",
        "                }, f)\n",
        "\n",
        "        elif self.method == 'deep':\n",
        "            model_path = path.replace('.xml', '.h5')\n",
        "            self.deep_model.save(model_path)\n",
        "\n",
        "            encoder_path = path.replace('.xml', '_encoder.pkl')\n",
        "            with open(encoder_path, 'wb') as f:\n",
        "                pickle.dump(self.label_encoder, f)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        if self.method in ['eigenfaces', 'lbph']:\n",
        "            self.recognizer.read(path)\n",
        "\n",
        "        elif self.method == 'ml':\n",
        "            with open(path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "                self.recognizer = data['model']\n",
        "                self.label_encoder = data['encoder']\n",
        "\n",
        "        elif self.method == 'deep':\n",
        "            model_path = path.replace('.xml', '.h5')\n",
        "            if os.path.exists(model_path):\n",
        "                self.deep_model = tf.keras.models.load_model(model_path)\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"Deep learning model not found at {model_path}\")\n",
        "\n",
        "            encoder_path = path.replace('.xml', '_encoder.pkl')\n",
        "            if os.path.exists(encoder_path):\n",
        "                with open(encoder_path, 'rb') as f:\n",
        "                    self.label_encoder = pickle.load(f)\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"Label encoder not found at {encoder_path}\")\n",
        "\n",
        "def train_face_recognition(data_dir='data/known_faces', method='deep'):\n",
        "    detector = FaceDetector(method='dnn')\n",
        "    recognizer = FaceRecognizer(method=method)\n",
        "\n",
        "    print(f\"Loading training images from {data_dir}...\")\n",
        "    images, labels = load_images_from_folder(data_dir)\n",
        "\n",
        "    if not images:\n",
        "        print(\"No training images found. Please add images to the data/known_faces directory.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Loaded {len(images)} images with {len(set(labels))} unique labels.\")\n",
        "\n",
        "    faces = []\n",
        "    valid_labels = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for img, label in zip(images, labels):\n",
        "        detected_faces = detector.detect_faces(img)\n",
        "\n",
        "        if len(detected_faces) == 1:\n",
        "            face_img = recognizer.extract_faces(img, detected_faces)[0]\n",
        "            faces.append(face_img)\n",
        "            valid_labels.append(label)\n",
        "\n",
        "    detection_time = time.time() - start_time\n",
        "    print(f\"Face detection completed in {detection_time:.2f} seconds\")\n",
        "\n",
        "    if not faces:\n",
        "        print(\"No faces detected in training images.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Extracted {len(faces)} faces for training.\")\n",
        "\n",
        "    print(\"Training face recognizer...\")\n",
        "    start_time = time.time()\n",
        "    recognizer.train(faces, valid_labels)\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    model_path = f'models/face_recognizer_{method}.xml'\n",
        "    recognizer.save_model(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    return recognizer\n",
        "\n",
        "def recognize_faces_in_image(image_path, detector, recognizer):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Could not load image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "    faces = detector.detect_faces(image)\n",
        "    detection_time = time.time() - start_time\n",
        "    print(f\"Detected {len(faces)} faces in {detection_time:.2f} seconds.\")\n",
        "\n",
        "    result_image = image.copy()\n",
        "\n",
        "    start_time = time.time()\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = image[y:y+h, x:x+w]\n",
        "\n",
        "        label, confidence = recognizer.predict(face)\n",
        "\n",
        "        cv2.rectangle(result_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        text = f\"{label} ({confidence:.2f}%)\"\n",
        "        cv2.putText(result_image, text, (x, y-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    recognition_time = time.time() - start_time\n",
        "    print(f\"Recognition completed in {recognition_time:.2f} seconds.\")\n",
        "\n",
        "    return result_image\n",
        "\n",
        "def process_video(video_path, detector, recognizer, output_path=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Could not open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    total_detection_time = 0\n",
        "    total_recognition_time = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    frames = []\n",
        "    max_frames = 100\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        detection_start = time.time()\n",
        "        faces = detector.detect_faces(frame)\n",
        "        detection_time = time.time() - detection_start\n",
        "        total_detection_time += detection_time\n",
        "\n",
        "        recognition_start = time.time()\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "\n",
        "            try:\n",
        "                label, confidence = recognizer.predict(face)\n",
        "\n",
        "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "                text = f\"{label} ({confidence:.2f}%)\"\n",
        "                cv2.putText(frame, text, (x, y-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "            except Exception as e:\n",
        "                print(f\"Error recognizing face: {e}\")\n",
        "\n",
        "        recognition_time = time.time() - recognition_start\n",
        "        total_recognition_time += recognition_time\n",
        "\n",
        "        current_fps = 1.0 / (detection_time + recognition_time) if (detection_time + recognition_time) > 0 else 0\n",
        "        cv2.putText(frame, f\"FPS: {current_fps:.2f}\", (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "        if output_path:\n",
        "            out.write(frame)\n",
        "\n",
        "        if frame_count <= max_frames:\n",
        "            frames.append(frame.copy())\n",
        "\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Processed {frame_count} frames\", end='\\r')\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
        "    avg_detection_time = total_detection_time / frame_count if frame_count > 0 else 0\n",
        "    avg_recognition_time = total_recognition_time / frame_count if frame_count > 0 else 0\n",
        "\n",
        "    print(f\"\\nPerformance Metrics:\")\n",
        "    print(f\"Total frames processed: {frame_count}\")\n",
        "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
        "    print(f\"Average detection time per frame: {avg_detection_time*1000:.2f} ms\")\n",
        "    print(f\"Average recognition time per frame: {avg_recognition_time*1000:.2f} ms\")\n",
        "\n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "\n",
        "    if frames:\n",
        "        print(\"\\nPreview of processed frames:\")\n",
        "        preview_frames = frames[::max(1, len(frames)//5)]\n",
        "        for i, frame in enumerate(preview_frames):\n",
        "            print(f\"Frame {i+1}/{len(preview_frames)}\")\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.imshow(frame_rgb)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    return output_path if output_path else None\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def process_webcam(detector, recognizer, num_frames=10):\n",
        "    js = \"\"\"\n",
        "    async function captureFrame() {\n",
        "        const div = document.createElement('div');\n",
        "        document.body.appendChild(div);\n",
        "        div.innerHTML = 'Loading webcam...';\n",
        "\n",
        "        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n",
        "            div.innerHTML = 'Webcam not supported in this browser';\n",
        "            return null;\n",
        "        }\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'none';\n",
        "        div.appendChild(video);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.style.display = 'none';\n",
        "        div.appendChild(canvas);\n",
        "\n",
        "        try {\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "            video.srcObject = stream;\n",
        "            video.play();\n",
        "            div.innerHTML = 'Webcam active. Capturing frame...';\n",
        "\n",
        "            await new Promise(resolve => video.onloadedmetadata = resolve);\n",
        "\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "\n",
        "            const ctx = canvas.getContext('2d');\n",
        "            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "            const imageData = canvas.toDataURL('image/jpeg');\n",
        "\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "\n",
        "            div.remove();\n",
        "\n",
        "            return imageData;\n",
        "        } catch (error) {\n",
        "            div.innerHTML = `Error accessing webcam: ${error.message}`;\n",
        "            return null;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    captureFrame();\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Accessing webcam...\")\n",
        "    print(\"Note: You may need to grant webcam access in your browser.\")\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        print(f\"\\nCapturing frame {i+1}/{num_frames}...\")\n",
        "\n",
        "        frame_data = eval_js(js)\n",
        "        if frame_data is None:\n",
        "            print(\"Failed to capture frame from webcam.\")\n",
        "            break\n",
        "\n",
        "        frame = js_to_image(frame_data)\n",
        "\n",
        "        faces = detector.detect_faces(frame)\n",
        "        print(f\"Detected {len(faces)} faces.\")\n",
        "\n",
        "        result_frame = frame.copy()\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "\n",
        "            try:\n",
        "                label, confidence = recognizer.predict(face)\n",
        "\n",
        "                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "                text = f\"{label} ({confidence:.2f}%)\"\n",
        "                cv2.putText(result_frame, text, (x, y-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "            except Exception as e:\n",
        "                print(f\"Error recognizing face: {e}\")\n",
        "\n",
        "        print(\"Processed frame:\")\n",
        "        result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.imshow(result_frame_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        time.sleep(3)\n",
        "\n",
        "def upload_images():\n",
        "    print(\"Please select one or more images to upload.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        with open(f'data/test_images/{filename}', 'wb') as f:\n",
        "            f.write(content)\n",
        "        print(f\"Saved {filename} to data/test_images/{filename}\")\n",
        "\n",
        "    return list(uploaded.keys())\n",
        "\n",
        "def upload_training_images(person_name):\n",
        "    person_dir = f'data/known_faces/{person_name}'\n",
        "    if not os.path.exists(person_dir):\n",
        "        os.makedirs(person_dir)\n",
        "        print(f\"Created directory: {person_dir}\")\n",
        "\n",
        "    print(f\"Please select one or more images of {person_name} to upload.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, content in uploaded.items():\n",
        "        with open(f'{person_dir}/{filename}', 'wb') as f:\n",
        "            f.write(content)\n",
        "        print(f\"Saved {filename} to {person_dir}/{filename}\")\n",
        "\n",
        "    return list(uploaded.keys())\n",
        "\n",
        "def download_file(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        files.download(file_path)\n",
        "        print(f\"Downloaded {file_path}\")\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "\n",
        "def add_person():\n",
        "    person_name = input(\"Enter the name of the person: \")\n",
        "\n",
        "    uploaded_files = upload_training_images(person_name)\n",
        "\n",
        "    if uploaded_files:\n",
        "        print(f\"Added {len(uploaded_files)} images for {person_name}.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"No images were uploaded.\")\n",
        "        return False\n",
        "\n",
        "def train_model():\n",
        "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
        "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
        "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
        "        method = 'deep'\n",
        "\n",
        "    recognizer = train_face_recognition(method=method)\n",
        "\n",
        "    if recognizer:\n",
        "        print(\"Training completed successfully.\")\n",
        "        return recognizer\n",
        "    else:\n",
        "        print(\"Training failed.\")\n",
        "        return None\n",
        "\n",
        "def process_image():\n",
        "    uploaded_files = upload_images()\n",
        "\n",
        "    if not uploaded_files:\n",
        "        print(\"No images were uploaded.\")\n",
        "        return\n",
        "\n",
        "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
        "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
        "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
        "        method = 'deep'\n",
        "\n",
        "    detector = FaceDetector(method='dnn')\n",
        "    recognizer = FaceRecognizer(method=method)\n",
        "\n",
        "    model_path = f'models/face_recognizer_{method}.xml'\n",
        "    if not os.path.exists(model_path) and method != 'deep':\n",
        "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
        "        return\n",
        "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
        "        print(f\"Deep learning model not found. Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    recognizer.load_model(model_path)\n",
        "\n",
        "    for filename in uploaded_files:\n",
        "        image_path = f'data/test_images/{filename}'\n",
        "\n",
        "        result = recognize_faces_in_image(image_path, detector, recognizer)\n",
        "\n",
        "        if result is not None:\n",
        "            output_path = f'data/test_images/result_{filename}'\n",
        "            cv2.imwrite(output_path, result)\n",
        "            print(f\"Result saved to {output_path}\")\n",
        "\n",
        "            display_image(result, title=f\"Face Recognition Result - {filename}\")\n",
        "\n",
        "            download = input(f\"Download the result for {filename}? (y/n): \")\n",
        "            if download.lower() == 'y':\n",
        "                download_file(output_path)\n",
        "\n",
        "def process_video_file():\n",
        "    print(\"Please select a video file to upload.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No video was uploaded.\")\n",
        "        return\n",
        "\n",
        "    video_filename = list(uploaded.keys())[0]\n",
        "    video_path = f'data/test_images/{video_filename}'\n",
        "    with open(video_path, 'wb') as f:\n",
        "        f.write(uploaded[video_filename])\n",
        "    print(f\"Saved {video_filename} to {video_path}\")\n",
        "\n",
        "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
        "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
        "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
        "        method = 'deep'\n",
        "\n",
        "    detector = FaceDetector(method='dnn')\n",
        "    recognizer = FaceRecognizer(method=method)\n",
        "\n",
        "    model_path = f'models/face_recognizer_{method}.xml'\n",
        "    if not os.path.exists(model_path) and method != 'deep':\n",
        "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
        "        return\n",
        "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
        "        print(f\"Deep learning model not found. Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    recognizer.load_model(model_path)\n",
        "\n",
        "    output_path = f'data/test_images/result_{video_filename}'\n",
        "    result = process_video(video_path, detector, recognizer, output_path)\n",
        "\n",
        "    if result:\n",
        "        print(f\"Processed video saved to {output_path}\")\n",
        "\n",
        "        download = input(f\"Download the processed video? (y/n): \")\n",
        "        if download.lower() == 'y':\n",
        "            download_file(output_path)\n",
        "\n",
        "def use_webcam():\n",
        "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
        "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
        "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
        "        method = 'deep'\n",
        "\n",
        "    detector = FaceDetector(method='dnn')\n",
        "    recognizer = FaceRecognizer(method=method)\n",
        "\n",
        "    model_path = f'models/face_recognizer_{method}.xml'\n",
        "    if not os.path.exists(model_path) and method != 'deep':\n",
        "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
        "        return\n",
        "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
        "        print(f\"Deep learning model not found. Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    recognizer.load_model(model_path)\n",
        "\n",
        "    num_frames = int(input(\"Enter the number of frames to capture (1-10): \"))\n",
        "    num_frames = max(1, min(10, num_frames))\n",
        "\n",
        "    process_webcam(detector, recognizer, num_frames)\n",
        "\n",
        "def main_menu():\n",
        "    while True:\n",
        "        print(\"\\n===== Face Detection and Recognition System =====\")\n",
        "        print(\"1. Add a person to the training dataset\")\n",
        "        print(\"2. Train the face recognition model\")\n",
        "        print(\"3. Process an image\")\n",
        "        print(\"4. Process a video\")\n",
        "        print(\"5. Use webcam\")\n",
        "        print(\"6. Check GPU performance\")\n",
        "        print(\"0. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (0-6): \")\n",
        "\n",
        "        if choice == '0':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        elif choice == '1':\n",
        "            add_person()\n",
        "        elif choice == '2':\n",
        "            train_model()\n",
        "        elif choice == '3':\n",
        "            process_image()\n",
        "        elif choice == '4':\n",
        "            process_video_file()\n",
        "        elif choice == '5':\n",
        "            use_webcam()\n",
        "        elif choice == '6':\n",
        "            results = benchmark_gpu()\n",
        "            print(\"\\nGPU Performance Results:\")\n",
        "            for device, result in results.items():\n",
        "                print(f\"Device: {device}\")\n",
        "                print(f\"  Type: {result['type']}\")\n",
        "                print(f\"  Time: {result['time']:.4f} seconds\")\n",
        "                print(f\"  Data Size: {result['data_size']}\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "main_menu()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}