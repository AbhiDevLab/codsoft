{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2351bc0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Face Detection and Recognition System for Google Colab\n",
    "# This file contains the complete code that you can copy and paste into a Colab notebook\n",
    "\n",
    "# Install required packages\n",
    "!pip install opencv-python-headless numpy matplotlib scikit-learn pillow tensorflow\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import urllib.request\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from google.colab import files\n",
    "from IPython.display import display, HTML\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Configure GPU memory growth to avoid OOM errors\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error configuring GPU: {e}\")\n",
    "\n",
    "# Create project directories\n",
    "directories = [\n",
    "    'data/known_faces',\n",
    "    'data/test_images',\n",
    "    'models'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "# Download Haar cascade model if it doesn't exist\n",
    "haar_path = 'models/haarcascade_frontalface_default.xml'\n",
    "if not os.path.exists(haar_path):\n",
    "    print(\"Downloading Haar cascade model...\")\n",
    "    url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "    urllib.request.urlretrieve(url, haar_path)\n",
    "    print(f\"Downloaded to {haar_path}\")\n",
    "\n",
    "# Download DNN face detector model if it doesn't exist\n",
    "prototxt_path = 'models/deploy.prototxt'\n",
    "model_path = 'models/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "if not os.path.exists(prototxt_path):\n",
    "    print(\"Downloading DNN prototxt...\")\n",
    "    prototxt_url = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\"\n",
    "    urllib.request.urlretrieve(prototxt_url, prototxt_path)\n",
    "    print(f\"Downloaded to {prototxt_path}\")\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Downloading DNN model...\")\n",
    "    model_url = \"https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "    print(f\"Downloaded to {model_path}\")\n",
    "\n",
    "# Utility Functions\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Load all images from a folder and its subfolders.\n",
    "    \n",
    "    Args:\n",
    "        folder: Path to the folder\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (images, labels)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for person_name in os.listdir(folder):\n",
    "        person_folder = os.path.join(folder, person_name)\n",
    "        \n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "            \n",
    "        for filename in os.listdir(person_folder):\n",
    "            img_path = os.path.join(person_folder, filename)\n",
    "            \n",
    "            if not os.path.isfile(img_path):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(person_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def display_image(image, title=None, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Display an image using matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        image: Image to display\n",
    "        title: Optional title\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Convert BGR to RGB for display\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def benchmark_gpu():\n",
    "    \"\"\"\n",
    "    Benchmark GPU performance for TensorFlow operations.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Test TensorFlow performance\n",
    "    try:\n",
    "        # Check if TensorFlow can see the GPU\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            # Create test data\n",
    "            data_size = 1000  # Matrix size\n",
    "            a = tf.random.normal((data_size, data_size))\n",
    "            b = tf.random.normal((data_size, data_size))\n",
    "            \n",
    "            # Warm up\n",
    "            c = tf.matmul(a, b)\n",
    "            \n",
    "            # Run test\n",
    "            start_time = time.time()\n",
    "            c = tf.matmul(a, b)\n",
    "            # Force execution\n",
    "            c_val = c.numpy()\n",
    "            end_time = time.time()\n",
    "            \n",
    "            for gpu in gpus:\n",
    "                results[gpu.name.decode('utf-8')] = {\n",
    "                    'type': 'TensorFlow',\n",
    "                    'time': end_time - start_time,\n",
    "                    'data_size': data_size\n",
    "                }\n",
    "                \n",
    "                print(f\"TensorFlow test on {gpu.name.decode('utf-8')} completed in {end_time - start_time:.4f} seconds\")\n",
    "        else:\n",
    "            print(\"TensorFlow cannot access any GPUs\")\n",
    "            \n",
    "            # Run CPU test for comparison\n",
    "            data_size = 1000  # Matrix size\n",
    "            a = np.random.rand(data_size, data_size).astype(np.float32)\n",
    "            b = np.random.rand(data_size, data_size).astype(np.float32)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            c = np.matmul(a, b)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            results['CPU'] = {\n",
    "                'type': 'NumPy',\n",
    "                'time': end_time - start_time,\n",
    "                'data_size': data_size\n",
    "            }\n",
    "            \n",
    "            print(f\"CPU test completed in {end_time - start_time:.4f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"TensorFlow benchmark failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Face Detector Class\n",
    "class FaceDetector:\n",
    "    \"\"\"Class for detecting faces in images using different methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, method='dnn', model_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the face detector.\n",
    "        \n",
    "        Args:\n",
    "            method (str): Detection method ('haar' or 'dnn')\n",
    "            model_path (str): Path to the model file\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        \n",
    "        if method == 'haar':\n",
    "            if model_path is None:\n",
    "                model_path = 'models/haarcascade_frontalface_default.xml'\n",
    "            self.detector = cv2.CascadeClassifier(model_path)\n",
    "        elif method == 'dnn':\n",
    "            # Load DNN face detector\n",
    "            prototxt_path = 'models/deploy.prototxt'\n",
    "            model_path = 'models/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "            \n",
    "            self.detector = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "            \n",
    "            # Use CUDA if available\n",
    "            try:\n",
    "                if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "                    self.detector.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "                    self.detector.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "                    print(\"Using CUDA for DNN face detection\")\n",
    "            except:\n",
    "                print(\"CUDA not available for OpenCV, using CPU\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported detection method: {method}\")\n",
    "    \n",
    "    def detect_faces(self, image, min_confidence=0.5):\n",
    "        \"\"\"\n",
    "        Detect faces in an image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (BGR format)\n",
    "            min_confidence: Minimum confidence threshold for DNN detection\n",
    "            \n",
    "        Returns:\n",
    "            List of face rectangles as (x, y, w, h)\n",
    "        \"\"\"\n",
    "        if self.method == 'haar':\n",
    "            # Convert to grayscale for Haar cascade\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.detector.detectMultiScale(\n",
    "                gray, \n",
    "                scaleFactor=1.1, \n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "            return faces\n",
    "        \n",
    "        # Use DNN for face detection\n",
    "        elif self.method == 'dnn':\n",
    "            h, w = image.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                cv2.resize(image, (300, 300)), \n",
    "                1.0, (300, 300), \n",
    "                (104.0, 177.0, 123.0)\n",
    "            )\n",
    "            \n",
    "            self.detector.setInput(blob)\n",
    "            detections = self.detector.forward()\n",
    "            \n",
    "            faces = []\n",
    "            for i in range(detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                \n",
    "                if confidence > min_confidence:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    \n",
    "                    # Convert to (x, y, w, h) format\n",
    "                    faces.append((startX, startY, endX - startX, endY - startY))\n",
    "            \n",
    "            return faces\n",
    "    \n",
    "    def draw_faces(self, image, faces, color=(0, 255, 0), thickness=2):\n",
    "        \"\"\"\n",
    "        Draw rectangles around detected faces.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            faces: List of face rectangles (x, y, w, h)\n",
    "            color: Rectangle color\n",
    "            thickness: Line thickness\n",
    "            \n",
    "        Returns:\n",
    "            Image with drawn rectangles\n",
    "        \"\"\"\n",
    "        img_copy = image.copy()\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img_copy, (x, y), (x + w, y + h), color, thickness)\n",
    "        return img_copy\n",
    "\n",
    "# Face Recognizer Class\n",
    "class FaceRecognizer:\n",
    "    \"\"\"Class for face recognition using various methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, method='eigenfaces'):\n",
    "        \"\"\"\n",
    "        Initialize the face recognizer.\n",
    "        \n",
    "        Args:\n",
    "            method (str): Recognition method ('eigenfaces', 'lbph', 'ml', or 'deep')\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.face_size = (100, 100)  # Standard size for face images\n",
    "        \n",
    "        # Initialize the recognizer based on the method\n",
    "        if method == 'eigenfaces':\n",
    "            self.recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "        elif method == 'lbph':\n",
    "            self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        elif method == 'ml':\n",
    "            # Using SVM for machine learning approach\n",
    "            self.recognizer = SVC(kernel='linear', probability=True)\n",
    "            self.label_encoder = LabelEncoder()\n",
    "        elif method == 'deep':\n",
    "            # Using a deep learning model for face recognition\n",
    "            self._create_deep_model()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported recognition method: {method}\")\n",
    "    \n",
    "    def _create_deep_model(self):\n",
    "        \"\"\"Create a deep learning model for face recognition.\"\"\"\n",
    "        # Create a simple CNN model for face recognition\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            # Output layer will be added during training when we know the number of classes\n",
    "        ])\n",
    "        \n",
    "        self.deep_model = model\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def preprocess_face(self, face):\n",
    "        \"\"\"\n",
    "        Preprocess a face image for recognition.\n",
    "        \n",
    "        Args:\n",
    "            face: Face image\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed face image\n",
    "        \"\"\"\n",
    "        # Resize to standard size\n",
    "        face = cv2.resize(face, self.face_size)\n",
    "        \n",
    "        # Convert to grayscale if not already\n",
    "        if len(face.shape) == 3:\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply histogram equalization for better contrast\n",
    "        face = cv2.equalizeHist(face)\n",
    "        \n",
    "        return face\n",
    "    \n",
    "    def extract_faces(self, image, face_locations):\n",
    "        \"\"\"\n",
    "        Extract face images from the main image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            face_locations: List of face rectangles (x, y, w, h)\n",
    "            \n",
    "        Returns:\n",
    "            List of extracted and preprocessed face images\n",
    "        \"\"\"\n",
    "        faces = []\n",
    "        for (x, y, w, h) in face_locations:\n",
    "            face = image[y:y+h, x:x+w]\n",
    "            faces.append(self.preprocess_face(face))\n",
    "        return faces\n",
    "    \n",
    "    def train(self, faces, labels):\n",
    "        \"\"\"\n",
    "        Train the face recognizer.\n",
    "        \n",
    "        Args:\n",
    "            faces: List of face images\n",
    "            labels: List of corresponding labels\n",
    "        \"\"\"\n",
    "        if self.method in ['eigenfaces', 'lbph']:\n",
    "            self.recognizer.train(faces, np.array(labels))\n",
    "        \n",
    "        elif self.method == 'ml':\n",
    "            # For ML approach, flatten the images\n",
    "            flattened_faces = [face.flatten() for face in faces]\n",
    "            encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "            self.recognizer.fit(flattened_faces, encoded_labels)\n",
    "        \n",
    "        elif self.method == 'deep':\n",
    "            # For deep learning approach\n",
    "            # Encode labels\n",
    "            encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "            num_classes = len(self.label_encoder.classes_)\n",
    "            \n",
    "            # Add output layer with correct number of classes\n",
    "            if len(self.deep_model.layers) == 10:  # If output layer not added yet\n",
    "                self.deep_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "            \n",
    "            # Compile the model\n",
    "            self.deep_model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Prepare data for training\n",
    "            # Reshape faces for CNN input (add channel dimension)\n",
    "            faces_array = np.array([face.reshape(self.face_size[0], self.face_size[1], 1) for face in faces])\n",
    "            \n",
    "            # Normalize pixel values\n",
    "            faces_array = faces_array / 255.0\n",
    "            \n",
    "            # Train the model\n",
    "            self.deep_model.fit(\n",
    "                faces_array, \n",
    "                encoded_labels,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2\n",
    "            )\n",
    "    \n",
    "    def predict(self, face):\n",
    "        \"\"\"\n",
    "        Predict the identity of a face.\n",
    "        \n",
    "        Args:\n",
    "            face: Preprocessed face image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (label, confidence)\n",
    "        \"\"\"\n",
    "        face = self.preprocess_face(face)\n",
    "        \n",
    "        if self.method in ['eigenfaces', 'lbph']:\n",
    "            label, confidence = self.recognizer.predict(face)\n",
    "            return label, confidence\n",
    "        \n",
    "        elif self.method == 'ml':\n",
    "            # For ML approach\n",
    "            face_flattened = face.flatten().reshape(1, -1)\n",
    "            label = self.recognizer.predict(face_flattened)[0]\n",
    "            proba = self.recognizer.predict_proba(face_flattened)[0]\n",
    "            confidence = proba[label] * 100\n",
    "            \n",
    "            # Convert numeric label back to original label\n",
    "            original_label = self.label_encoder.inverse_transform([label])[0]\n",
    "            return original_label, confidence\n",
    "        \n",
    "        elif self.method == 'deep':\n",
    "            # For deep learning approach\n",
    "            # Reshape and normalize the face\n",
    "            face_array = face.reshape(1, self.face_size[0], self.face_size[1], 1) / 255.0\n",
    "            \n",
    "            # Get prediction\n",
    "            predictions = self.deep_model.predict(face_array)\n",
    "            label_index = np.argmax(predictions[0])\n",
    "            confidence = predictions[0][label_index] * 100\n",
    "            \n",
    "            # Convert numeric label back to original label\n",
    "            original_label = self.label_encoder.inverse_transform([label_index])[0]\n",
    "            return original_label, confidence\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the trained model to a file.\"\"\"\n",
    "        if self.method in ['eigenfaces', 'lbph']:\n",
    "            self.recognizer.save(path)\n",
    "        \n",
    "        elif self.method == 'ml':\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'model': self.recognizer,\n",
    "                    'encoder': self.label_encoder\n",
    "                }, f)\n",
    "        \n",
    "        elif self.method == 'deep':\n",
    "            # Save the Keras model\n",
    "            model_path = path.replace('.xml', '.h5')\n",
    "            self.deep_model.save(model_path)\n",
    "            \n",
    "            # Save the label encoder\n",
    "            encoder_path = path.replace('.xml', '_encoder.pkl')\n",
    "            with open(encoder_path, 'wb') as f:\n",
    "                pickle.dump(self.label_encoder, f)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        \"\"\"Load a trained model from a file.\"\"\"\n",
    "        if self.method in ['eigenfaces', 'lbph']:\n",
    "            self.recognizer.read(path)\n",
    "        \n",
    "        elif self.method == 'ml':\n",
    "            with open(path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.recognizer = data['model']\n",
    "                self.label_encoder = data['encoder']\n",
    "        \n",
    "        elif self.method == 'deep':\n",
    "            # Load the Keras model\n",
    "            model_path = path.replace('.xml', '.h5')\n",
    "            if os.path.exists(model_path):\n",
    "                self.deep_model = tf.keras.models.load_model(model_path)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Deep learning model not found at {model_path}\")\n",
    "            \n",
    "            # Load the label encoder\n",
    "            encoder_path = path.replace('.xml', '_encoder.pkl')\n",
    "            if os.path.exists(encoder_path):\n",
    "                with open(encoder_path, 'rb') as f:\n",
    "                    self.label_encoder = pickle.load(f)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Label encoder not found at {encoder_path}\")\n",
    "\n",
    "# Training Function\n",
    "def train_face_recognition(data_dir='data/known_faces', method='deep'):\n",
    "    \"\"\"Train the face recognition model.\"\"\"\n",
    "    # Initialize face detector and recognizer\n",
    "    detector = FaceDetector(method='dnn')\n",
    "    recognizer = FaceRecognizer(method=method)\n",
    "    \n",
    "    # Load training images\n",
    "    print(f\"Loading training images from {data_dir}...\")\n",
    "    images, labels = load_images_from_folder(data_dir)\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No training images found. Please add images to the data/known_faces directory.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images with {len(set(labels))} unique labels.\")\n",
    "    \n",
    "    # Extract faces from images\n",
    "    faces = []\n",
    "    valid_labels = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for img, label in zip(images, labels):\n",
    "        detected_faces = detector.detect_faces(img)\n",
    "        \n",
    "        if len(detected_faces) == 1:  # Only use images with exactly one face\n",
    "            face_img = recognizer.extract_faces(img, detected_faces)[0]\n",
    "            faces.append(face_img)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    detection_time = time.time() - start_time\n",
    "    print(f\"Face detection completed in {detection_time:.2f} seconds\")\n",
    "    \n",
    "    if not faces:\n",
    "        print(\"No faces detected in training images.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Extracted {len(faces)} faces for training.\")\n",
    "    \n",
    "    # Train the recognizer\n",
    "    print(\"Training face recognizer...\")\n",
    "    start_time = time.time()\n",
    "    recognizer.train(faces, valid_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = f'models/face_recognizer_{method}.xml'\n",
    "    recognizer.save_model(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return recognizer\n",
    "\n",
    "# Image Processing Function\n",
    "def recognize_faces_in_image(image_path, detector, recognizer):\n",
    "    \"\"\"Recognize faces in an image.\"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Detect faces\n",
    "    start_time = time.time()\n",
    "    faces = detector.detect_faces(image)\n",
    "    detection_time = time.time() - start_time\n",
    "    print(f\"Detected {len(faces)} faces in {detection_time:.2f} seconds.\")\n",
    "    \n",
    "    # Draw rectangles and labels\n",
    "    result_image = image.copy()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        \n",
    "        # Recognize the face\n",
    "        label, confidence = recognizer.predict(face)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(result_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label\n",
    "        text = f\"{label} ({confidence:.2f}%)\"\n",
    "        cv2.putText(result_image, text, (x, y-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "    recognition_time = time.time() - start_time\n",
    "    print(f\"Recognition completed in {recognition_time:.2f} seconds.\")\n",
    "    \n",
    "    return result_image\n",
    "\n",
    "# Video Processing Function\n",
    "def process_video(video_path, detector, recognizer, output_path=None):\n",
    "    \"\"\"Process a video for face recognition.\"\"\"\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Could not open video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Create video writer if output path is provided\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Performance metrics\n",
    "    frame_count = 0\n",
    "    total_detection_time = 0\n",
    "    total_recognition_time = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process frames\n",
    "    frames = []\n",
    "    max_frames = 100  # Limit number of frames to process for preview\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detect faces\n",
    "        detection_start = time.time()\n",
    "        faces = detector.detect_faces(frame)\n",
    "        detection_time = time.time() - detection_start\n",
    "        total_detection_time += detection_time\n",
    "        \n",
    "        # Draw rectangles and labels\n",
    "        recognition_start = time.time()\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Recognize the face\n",
    "            try:\n",
    "                label, confidence = recognizer.predict(face)\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw label\n",
    "                text = f\"{label} ({confidence:.2f}%)\"\n",
    "                cv2.putText(frame, text, (x, y-10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error recognizing face: {e}\")\n",
    "        \n",
    "        recognition_time = time.time() - recognition_start\n",
    "        total_recognition_time += recognition_time\n",
    "        \n",
    "        # Add FPS info to frame\n",
    "        current_fps = 1.0 / (detection_time + recognition_time) if (detection_time + recognition_time) > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {current_fps:.2f}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "        # Write the frame\n",
    "        if output_path:\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Store frame for preview (limit to max_frames)\n",
    "        if frame_count <= max_frames:\n",
    "            frames.append(frame.copy())\n",
    "        \n",
    "        # Print progress\n",
    "        if frame_count % 10 == 0:\n",
    "            print(f\"Processed {frame_count} frames\", end='\\r')\n",
    "    \n",
    "    # Calculate and display performance metrics\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "    avg_detection_time = total_detection_time / frame_count if frame_count > 0 else 0\n",
    "    avg_recognition_time = total_recognition_time / frame_count if frame_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "    print(f\"Average detection time per frame: {avg_detection_time*1000:.2f} ms\")\n",
    "    print(f\"Average recognition time per frame: {avg_recognition_time*1000:.2f} ms\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    \n",
    "    # Display a preview of processed frames\n",
    "    if frames:\n",
    "        print(\"\\nPreview of processed frames:\")\n",
    "        # Display a few frames as a preview\n",
    "        preview_frames = frames[::max(1, len(frames)//5)]  # Take up to 5 frames evenly spaced\n",
    "        for i, frame in enumerate(preview_frames):\n",
    "            print(f\"Frame {i+1}/{len(preview_frames)}\")\n",
    "            # Convert BGR to RGB for display\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(frame_rgb)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    return output_path if output_path else None\n",
    "\n",
    "# Webcam Access Function\n",
    "def js_to_image(js_reply):\n",
    "    \"\"\"\n",
    "    Convert JS canvas image to OpenCV image.\n",
    "    \"\"\"\n",
    "    # Decode base64 image\n",
    "    image_bytes = b64decode(js_reply.split(',')[1])\n",
    "    # Convert to numpy array\n",
    "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    # Decode to OpenCV image\n",
    "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "    return img\n",
    "\n",
    "def process_webcam(detector, recognizer, num_frames=10):\n",
    "    \"\"\"\n",
    "    Process webcam feed for face recognition in Google Colab.\n",
    "    \n",
    "    Args:\n",
    "        detector: Face detector instance\n",
    "        recognizer: Face recognizer instance\n",
    "        num_frames: Number of frames to process\n",
    "    \"\"\"\n",
    "    # JavaScript to access webcam\n",
    "    js = \"\"\"\n",
    "    async function captureFrame() {\n",
    "        const div = document.createElement('div');\n",
    "        document.body.appendChild(div);\n",
    "        div.innerHTML = 'Loading webcam...';\n",
    "        \n",
    "        // Check if webcam access is supported\n",
    "        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n",
    "            div.innerHTML = 'Webcam not supported in this browser';\n",
    "            return null;\n",
    "        }\n",
    "        \n",
    "        // Create video element\n",
    "        const video = document.createElement('video');\n",
    "        video.style.display = 'none';\n",
    "        div.appendChild(video);\n",
    "        \n",
    "        // Create canvas for capturing frames\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.style.display = 'none';\n",
    "        div.appendChild(canvas);\n",
    "        \n",
    "        // Get webcam stream\n",
    "        try {\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
    "            video.srcObject = stream;\n",
    "            video.play();\n",
    "            div.innerHTML = 'Webcam active. Capturing frame...';\n",
    "            \n",
    "            // Wait for video to be ready\n",
    "            await new Promise(resolve => video.onloadedmetadata = resolve);\n",
    "            \n",
    "            // Set canvas size to match video\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            \n",
    "            // Draw video frame to canvas\n",
    "            const ctx = canvas.getContext('2d');\n",
    "            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
    "            \n",
    "            // Get image data as base64\n",
    "            const imageData = canvas.toDataURL('image/jpeg');\n",
    "            \n",
    "            // Stop the stream\n",
    "            stream.getTracks().forEach(track => track.stop());\n",
    "            \n",
    "            // Clean up\n",
    "            div.remove();\n",
    "            \n",
    "            return imageData;\n",
    "        } catch (error) {\n",
    "            div.innerHTML = `Error accessing webcam: ${error.message}`;\n",
    "            return null;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    captureFrame();\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Accessing webcam...\")\n",
    "    print(\"Note: You may need to grant webcam access in your browser.\")\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        print(f\"\\nCapturing frame {i+1}/{num_frames}...\")\n",
    "        \n",
    "        # Capture frame from webcam\n",
    "        frame_data = eval_js(js)\n",
    "        if frame_data is None:\n",
    "            print(\"Failed to capture frame from webcam.\")\n",
    "            break\n",
    "        \n",
    "        # Convert to OpenCV image\n",
    "        frame = js_to_image(frame_data)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detector.detect_faces(frame)\n",
    "        print(f\"Detected {len(faces)} faces.\")\n",
    "        \n",
    "        # Draw rectangles and labels\n",
    "        result_frame = frame.copy()\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the face\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Recognize the face\n",
    "            try:\n",
    "                label, confidence = recognizer.predict(face)\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw label\n",
    "                text = f\"{label} ({confidence:.2f}%)\"\n",
    "                cv2.putText(result_frame, text, (x, y-10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error recognizing face: {e}\")\n",
    "        \n",
    "        # Display the result\n",
    "        print(\"Processed frame:\")\n",
    "        # Convert BGR to RGB for display\n",
    "        result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(result_frame_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Wait a bit before capturing the next frame\n",
    "        time.sleep(1)\n",
    "\n",
    "# File Upload and Download Functions\n",
    "def upload_images():\n",
    "    \"\"\"Upload images to Google Colab.\"\"\"\n",
    "    print(\"Please select one or more images to upload.\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Save uploaded files to data/test_images\n",
    "    for filename, content in uploaded.items():\n",
    "        with open(f'data/test_images/{filename}', 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Saved {filename} to data/test_images/{filename}\")\n",
    "    \n",
    "    return list(uploaded.keys())\n",
    "\n",
    "def upload_training_images(person_name):\n",
    "    \"\"\"Upload training images for a specific person.\"\"\"\n",
    "    # Create directory for the person if it doesn't exist\n",
    "    person_dir = f'data/known_faces/{person_name}'\n",
    "    if not os.path.exists(person_dir):\n",
    "        os.makedirs(person_dir)\n",
    "        print(f\"Created directory: {person_dir}\")\n",
    "    \n",
    "    print(f\"Please select one or more images of {person_name} to upload.\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Save uploaded files to data/known_faces/{person_name}\n",
    "    for filename, content in uploaded.items():\n",
    "        with open(f'{person_dir}/{filename}', 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Saved {filename} to {person_dir}/{filename}\")\n",
    "    \n",
    "    return list(uploaded.keys())\n",
    "\n",
    "def download_file(file_path):\n",
    "    \"\"\"Download a file from Google Colab.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        files.download(file_path)\n",
    "        print(f\"Downloaded {file_path}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Main Functions\n",
    "def add_person():\n",
    "    \"\"\"Add a new person to the training dataset.\"\"\"\n",
    "    person_name = input(\"Enter the name of the person: \")\n",
    "    \n",
    "    # Upload images for the person\n",
    "    uploaded_files = upload_training_images(person_name)\n",
    "    \n",
    "    if uploaded_files:\n",
    "        print(f\"Added {len(uploaded_files)} images for {person_name}.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No images were uploaded.\")\n",
    "        return False\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Train the face recognition model.\"\"\"\n",
    "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
    "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
    "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
    "        method = 'deep'\n",
    "    \n",
    "    recognizer = train_face_recognition(method=method)\n",
    "    \n",
    "    if recognizer:\n",
    "        print(\"Training completed successfully.\")\n",
    "        return recognizer\n",
    "    else:\n",
    "        print(\"Training failed.\")\n",
    "        return None\n",
    "\n",
    "def process_image():\n",
    "    \"\"\"Process an image for face recognition.\"\"\"\n",
    "    # Upload an image\n",
    "    uploaded_files = upload_images()\n",
    "    \n",
    "    if not uploaded_files:\n",
    "        print(\"No images were uploaded.\")\n",
    "        return\n",
    "    \n",
    "    # Select recognition method\n",
    "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
    "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
    "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
    "        method = 'deep'\n",
    "    \n",
    "    # Load models\n",
    "    detector = FaceDetector(method='dnn')\n",
    "    recognizer = FaceRecognizer(method=method)\n",
    "    \n",
    "    model_path = f'models/face_recognizer_{method}.xml'\n",
    "    if not os.path.exists(model_path) and method != 'deep':\n",
    "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "        return\n",
    "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "        print(f\"Deep learning model not found. Please train the model first.\")\n",
    "        return\n",
    "    \n",
    "    recognizer.load_model(model_path)\n",
    "    \n",
    "    # Process each uploaded image\n",
    "    for filename in uploaded_files:\n",
    "        image_path = f'data/test_images/{filename}'\n",
    "        \n",
    "        # Process the image\n",
    "        result = recognize_faces_in_image(image_path, detector, recognizer)\n",
    "        \n",
    "        if result is not None:\n",
    "            # Save the result\n",
    "            output_path = f'data/test_images/result_{filename}'\n",
    "            cv2.imwrite(output_path, result)\n",
    "            print(f\"Result saved to {output_path}\")\n",
    "            \n",
    "            # Display the result\n",
    "            display_image(result, title=f\"Face Recognition Result - {filename}\")\n",
    "            \n",
    "            # Offer to download the result\n",
    "            download = input(f\"Download the result for {filename}? (y/n): \")\n",
    "            if download.lower() == 'y':\n",
    "                download_file(output_path)\n",
    "\n",
    "def process_video_file():\n",
    "    \"\"\"Process a video file for face recognition.\"\"\"\n",
    "    # Upload a video\n",
    "    print(\"Please select a video file to upload.\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if not uploaded:\n",
    "        print(\"No video was uploaded.\")\n",
    "        return\n",
    "    \n",
    "    # Save uploaded video\n",
    "    video_filename = list(uploaded.keys())[0]\n",
    "    video_path = f'data/test_images/{video_filename}'\n",
    "    with open(video_path, 'wb') as f:\n",
    "        f.write(uploaded[video_filename])\n",
    "    print(f\"Saved {video_filename} to {video_path}\")\n",
    "    \n",
    "    # Select recognition method\n",
    "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
    "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
    "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
    "        method = 'deep'\n",
    "    \n",
    "    # Load models\n",
    "    detector = FaceDetector(method='dnn')\n",
    "    recognizer = FaceRecognizer(method=method)\n",
    "    \n",
    "    model_path = f'models/face_recognizer_{method}.xml'\n",
    "    if not os.path.exists(model_path) and method != 'deep':\n",
    "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "        return\n",
    "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "        print(f\"Deep learning model not found. Please train the model first.\")\n",
    "        return\n",
    "    \n",
    "    recognizer.load_model(model_path)\n",
    "    \n",
    "    # Process the video\n",
    "    output_path = f'data/test_images/result_{video_filename}'\n",
    "    result = process_video(video_path, detector, recognizer, output_path)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"Processed video saved to {output_path}\")\n",
    "        \n",
    "        # Offer to download the result\n",
    "        download = input(f\"Download the processed video? (y/n): \")\n",
    "        if download.lower() == 'y':\n",
    "            download_file(output_path)\n",
    "\n",
    "def use_webcam():\n",
    "    \"\"\"Use webcam for face recognition.\"\"\"\n",
    "    # Select recognition method\n",
    "    method = input(\"Enter the recognition method (eigenfaces, lbph, ml, deep): \")\n",
    "    if method not in ['eigenfaces', 'lbph', 'ml', 'deep']:\n",
    "        print(f\"Invalid method: {method}. Using 'deep' as default.\")\n",
    "        method = 'deep'\n",
    "    \n",
    "    # Load models\n",
    "    detector = FaceDetector(method='dnn')\n",
    "    recognizer = FaceRecognizer(method=method)\n",
    "    \n",
    "    model_path = f'models/face_recognizer_{method}.xml'\n",
    "    if not os.path.exists(model_path) and method != 'deep':\n",
    "        print(f\"Model not found: {model_path}. Please train the model first.\")\n",
    "        return\n",
    "    elif method == 'deep' and not os.path.exists(model_path.replace('.xml', '.h5')):\n",
    "        print(f\"Deep learning model not found. Please train the model first.\")\n",
    "        return\n",
    "    \n",
    "    recognizer.load_model(model_path)\n",
    "    \n",
    "    # Process webcam feed\n",
    "    num_frames = int(input(\"Enter the number of frames to capture (1-10): \"))\n",
    "    num_frames = max(1, min(10, num_frames))  # Limit to 1-10 frames\n",
    "    \n",
    "    process_webcam(detector, recognizer, num_frames)\n",
    "\n",
    "# Main Menu\n",
    "def main_menu():\n",
    "    \"\"\"Display the main menu and handle user input.\"\"\"\n",
    "    while True:\n",
    "        print(\"\\n===== Face Detection and Recognition System =====\")\n",
    "        print(\"1. Add a person to the training dataset\")\n",
    "        print(\"2. Train the face recognition model\")\n",
    "        print(\"3. Process an image\")\n",
    "        print(\"4. Process a video\")\n",
    "        print(\"5. Use webcam\")\n",
    "        print(\"6. Check GPU performance\")\n",
    "        print(\"0. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (0-6): \")\n",
    "        \n",
    "        if choice == '0':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        elif choice == '1':\n",
    "            add_person()\n",
    "        elif choice == '2':\n",
    "            train_model()\n",
    "        elif choice == '3':\n",
    "            process_image()\n",
    "        elif choice == '4':\n",
    "            process_video_file()\n",
    "        elif choice == '5':\n",
    "            use_webcam()\n",
    "        elif choice == '6':\n",
    "            results = benchmark_gpu()\n",
    "            print(\"\\nGPU Performance Results:\")\n",
    "            for device, result in results.items():\n",
    "                print(f\"Device: {device}\")\n",
    "                print(f\"  Type: {result['type']}\")\n",
    "                print(f\"  Time: {result['time']:.4f} seconds\")\n",
    "                print(f\"  Data Size: {result['data_size']}\")\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "# Run the main menu\n",
    "main_menu()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
